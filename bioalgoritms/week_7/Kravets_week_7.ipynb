{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepairing functions for alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas\n",
    "import scipy as scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to work with strings and profiles\n",
    "\n",
    "def str_to_profile(string):\n",
    "    return [{col : 1} for col in string]\n",
    "\n",
    "def profile_to_str(profile):\n",
    "    return ''.join(tuple(col.keys())[0] for col in profile)\n",
    "\n",
    "# Pairwise alignment\n",
    "\n",
    "def align_pairwise(a, b, M, score_needed=False): # a и b - profiles, M - weight matrix\n",
    "    \n",
    "    # !!!!Вставим функции сюда, чтобы не волноваться о пространстве имён!!!\n",
    "    \n",
    "    # Weight for alignment\n",
    "    def weight(a, b, M):\n",
    "        var_1, var_2 = 0, 0\n",
    "        for s_a in a:\n",
    "            for s_b in b:\n",
    "                var_1 += a[s_a]*b[s_b] * M[amino_ind[s_a], amino_ind[s_b]]\n",
    "                var_2 += a[s_a]*b[s_b]\n",
    "        return var_1/var_2\n",
    "\n",
    "    # Merging two profiles\n",
    "    def merge(a, b):\n",
    "        merge = a.copy()\n",
    "        for key in b:\n",
    "            merge[key] = merge.get(key, 0) + b[key]\n",
    "        return merge\n",
    "\n",
    "    # Fulfiling borders\n",
    "    def gap_w(s0, s1_w):\n",
    "        w = np.zeros((len(s0)+1))\n",
    "        for i in range(1, len(s0)+1):\n",
    "            w[i] = w[i-1] + weight(s0[i-1], {'-': s1_w}, M)\n",
    "        return w\n",
    "    \n",
    "    a_w, b_w = sum(a[0].values()), sum(b[0].values())\n",
    "    \n",
    "    # Making our alignment-table\n",
    "    \n",
    "    n, m = len(a), len(b)\n",
    "    D = np.empty((n+1, m+1))\n",
    "    D[:,0] = gap_w(a, b_w)\n",
    "    D[0,:] = gap_w(b, a_w)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            a_gap = D[i, j-1] + weight(b[j-1], {'-': a_w}, M)\n",
    "            b_gap = D[i-1, j] + weight(a[i-1], {'-': b_w}, M)\n",
    "            match = D[i-1, j-1] + weight(a[i-1], b[j-1], M)\n",
    "            D[i, j] = max(a_gap, b_gap, match)\n",
    "\n",
    "    # Making consensus profile\n",
    "    i, j = n, m\n",
    "    consensus = []\n",
    "    \n",
    "    if score_needed:\n",
    "        # For printifs\n",
    "        return D[-1,-1] \n",
    "\n",
    "    while i + j > 0:\n",
    "        if D[i, j] == D[i-1, j] + weight(a[i-1], {'-': b_w}, M):\n",
    "            consensus.append(merge(a[i-1], {'-': b_w}))\n",
    "            i -= 1\n",
    "        elif D[i, j] == D[i, j-1] + weight(b[j-1], {'-': a_w}, M):\n",
    "            consensus.append(merge(b[j-1], {'-': a_w}))\n",
    "            j -= 1\n",
    "        else:\n",
    "            consensus.append(merge(b[j-1], a[i-1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    return consensus[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Pair Group Method with arithmetic mean\n",
    "\n",
    "def WPGMA(ind_in, A_in):\n",
    "    \n",
    "    # Finding min elem\n",
    "    argmin = lambda arr: np.unravel_index(arr.argmin(), arr.shape)\n",
    "    \n",
    "    # Converting A_in\n",
    "    ind = ind_in.copy()\n",
    "    A = A_in.copy()\n",
    "    A -= np.tri(*A.shape)\n",
    "    A = A.flatten()\n",
    "    A[A < 0] = np.inf\n",
    "    A = A.reshape((len(ind), len(ind)))\n",
    "    A[-1,:] = 0\n",
    "\n",
    "    # Constructing tree\n",
    "    while len(ind)-1:\n",
    "        i, j = argmin(A[:-1,:])\n",
    "        w = A[i,j]\n",
    "        \n",
    "        # dealing with i and i,j\n",
    "        ind[i] = '(' + ind[i] + ':' + str(w/2 - A[-1,i]) + ', ' + ind[j] + ':' + str(w/2 - A[-1,j]) + ')'\n",
    "        del ind[j]\n",
    "        A[:-1,i] = (A[:-1,i] + A[:-1,j])/2\n",
    "        A[-1,i] += w/2 - A[-1,i]\n",
    "        \n",
    "        # deleting i-string and j-column\n",
    "        \n",
    "        if j == A.shape[0] - 1:\n",
    "            A = np.hstack((A[:,:j],A[:,j+1:]))\n",
    "        else:\n",
    "            A = np.vstack((np.hstack((A[:j,:j],A[:j,j+1:])),np.hstack((A[j+1:,:j],A[j+1:,j+1:]))))\n",
    "        \n",
    "    return ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating table for creating tree\n",
    "\n",
    "def mutation_dist(string_mass, W):\n",
    "    \n",
    "    n = len(string_mass)\n",
    "    ind = list(string_mass.keys())\n",
    "    M = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            M[i,j] = -align_pairwise(string_mass[ind[i]], string_mass[ind[j]], W, score_needed=True)\n",
    "            \n",
    "    M[M < 0] -= (M.min() - 1)\n",
    "    \n",
    "    return ind, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating consensus for tree\n",
    "\n",
    "def multiple_alignment(strings_mass, tree, W):\n",
    "    \n",
    "    tr = tree\n",
    "    i = len(strings_mass)\n",
    "    strings_tab = strings_mass.copy()\n",
    "    \n",
    "    while re.search(r'\\((s_\\d+)[^\\)^\\(]+?(s_\\d+).+?\\)', tr):\n",
    "        \n",
    "        dns = re.findall(r'\\((s_\\d+)[^\\)^\\(]+?(s_\\d+).+?\\)', tr)\n",
    "        \n",
    "        for node in dns:\n",
    "            tr = re.sub(r'\\({}[^\\)^\\(]+?{}.+?\\)'.format(*node), 's_' + str(i), tr)\n",
    "            strings_tab['s_'+str(i)] = align_pairwise(strings_tab[node[0]], strings_tab[node[1]], W)\n",
    "            i += 1\n",
    "\n",
    "    return strings_tab[tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment string profile with consensus\n",
    "\n",
    "def align_pair_cons(cons, s, M): # cons and s - profiles, M - weight matrix\n",
    "    \n",
    "    cons_w, s_w = sum(cons[0].values()), sum(s[0].values())\n",
    "    \n",
    "    # Weight for alignment\n",
    "    def weight(a, b, M):\n",
    "        var_1, var_2 = 0, 0\n",
    "        for s_a in a:\n",
    "            for s_b in b:\n",
    "                var_1 += a[s_a]*b[s_b] * M[amino_ind[s_a], amino_ind[s_b]]\n",
    "                var_2 += a[s_a]*b[s_b]\n",
    "        return var_1/var_2\n",
    "\n",
    "    # Merging two profiles\n",
    "    def merge(a, b):\n",
    "        merge = a.copy()\n",
    "        for key in b:\n",
    "            merge[key] = merge.get(key, 0) + b[key]\n",
    "        return merge\n",
    "\n",
    "    # Fulfiling borders\n",
    "    def gap_w(s0, s1_w):\n",
    "        w = np.zeros((len(s0)+1))\n",
    "        for i in range(1, len(s0)+1):\n",
    "            w[i] = w[i-1] + weight(s0[i-1], {'-': s1_w}, M)\n",
    "        return w\n",
    "    \n",
    "    # Fulfiling table\n",
    "    n, m = len(cons), len(s)\n",
    "    D = np.empty((n+1, m+1))\n",
    "    D[:,0] = gap_w(cons, s_w)\n",
    "    D[0,:] = gap_w(s, cons_w)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            s_gap = D[i-1, j] + weight(cons[i-1], {'-': s_w}, M)\n",
    "            match = D[i-1, j-1] + weight(cons[i-1], s[j-1], M)\n",
    "            D[i, j] = max(s_gap, match)\n",
    "            \n",
    "    # Making alignments\n",
    "    \n",
    "    i, j = n, m\n",
    "    s_to_cons = []\n",
    "\n",
    "    while i + j > 0:\n",
    "        if D[i, j] == D[i-1, j] + weight(cons[i-1], {'-': s_w}, M):\n",
    "            s_to_cons.append({'-': 1})\n",
    "            i -= 1\n",
    "        else:\n",
    "            s_to_cons.append(s[j-1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "                \n",
    "    return profile_to_str(s_to_cons[::-1]).replace('-','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading PAM_250\n",
    "\n",
    "PAM_250 = np.empty((25,25), dtype=np.int)\n",
    "ind = {}\n",
    "\n",
    "with open('PAM_250.txt', 'r') as f:\n",
    "    amino = f.readline().split()[1:]\n",
    "    amino_ind = {amino[i]:i for i in range(25)}\n",
    "    for i in range(25):\n",
    "        PAM_250[i,:] = np.array(f.readline().split()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another attempts is to take default match = 1, mismatch = -1, gap = -1\n",
    "\n",
    "PAM_default = np.diag(np.ones(25, dtype=np.int)*2) - np.ones((25,25), dtype=np.int)\n",
    "PAM_default[-1,-1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем независимо мутировавшие аминокислотные последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random mutations in our string\n",
    "\n",
    "def mutations(string, num_insertion, num_deletion, max_len):\n",
    "    for _ in range(num_insertion):\n",
    "        pos= np.random.randint(0, len(string)-1)\n",
    "        insertion = np.random.randint(0, max_len)\n",
    "        string = string[:pos] + ''.join([amino[np.random.randint(0, 19)] for _ in range(insertion)]) + string[pos:]\n",
    "    for _ in range(num_deletion):\n",
    "        pos = np.random.randint(0, len(string)-1)\n",
    "        dlt = np.random.randint(0, max_len)\n",
    "        string = string[:pos] + string[pos+dlt:]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating massive of peptids\n",
    "\n",
    "def mutation_peptids(alphabet, max_ind):\n",
    "    mother_seq = ''.join([alphabet[np.random.randint(0, max_ind)] for _ in range(40)])\n",
    "    peptids = {}\n",
    "    for i in range(20):\n",
    "        peptids['s_' + str(i)] = mutations(mother_seq, np.random.randint(1, 5), np.random.randint(1, 5), 4)\n",
    "\n",
    "    for s in peptids:\n",
    "        print(peptids[s])\n",
    "        peptids[s] = str_to_profile(peptids[s])\n",
    "\n",
    "    return peptids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADQRRNGGQKCNICGGERIDIDHRGAQNCDRIWPCIDD\n",
      "CHQGEAEDQRRNGGCNCGGERDIDHNLYRGAGQNCDIDD\n",
      "CHQNGEAEDQRIWWRNGGCICGGERIDIDHICRGANCDRCIDD\n",
      "CHQGEAEDQRRNGGCNICGNPGERIDIRGAGQNCDRDD\n",
      "CHQGEDNQRRNGGCNICGGIFERIDIDHRGSAGQNCDRCIDD\n",
      "CHQGEAEDQRRNGGCNICGGERIDIDHGKMYSMQNCDRCIDD\n",
      "CHQGDQRRNFREGGCNICGGERIDIDHRGAGQNCDRCIDD\n",
      "CHQGEAEAIIDQRRMGNGGCEWANIDIDHRGAGQNCDRCIDD\n",
      "HQGEAEDSMMQRRGWCNICGGERILCFDIDHRGAGQNCCIDD\n",
      "CHQGEAEDQNGGCNICGIERIDIDHRGAGQNCDRCIDD\n",
      "HKCHQGEAEDQRRNGGLCNICGGERTIDHRGAGQNCDRCIDD\n",
      "CKIHQGEAEDQRRNHGGCNTHYICGGERIIDHRGAGQNCDRCIDD\n",
      "CHQGEADQRRNGGCNICGGERIDIDHGQNCIDD\n",
      "LFCHQGEAEDQRRNGGERIDIDHRGAGQNCDRCIDD\n",
      "CHQNKCHGEAEDQRRNMPGGCNICGGERIDIDHRGAGQNCDRCIDD\n",
      "CHQGEAEDQRRYHCNICGGERIDIDHRGAGQNCDRCIDD\n",
      "CHQGEAERRNGGCNIGTCGGERIDHRQNCDRCFSWIDD\n",
      "CHQGEAEDQRRCNGGCNICGQSRIDIDHRGAGQNCDRCIDD\n",
      "CHAEHQEDQRRNGGCNGLWDGERIDIDHRGAGQNCDRCIDD\n",
      "HQGEAQRRNGGCNICGGERIDIDPNHRGAGQNNCIDD\n"
     ]
    }
   ],
   "source": [
    "strings_mass = mutation_peptids(amino, 10) # 10 - because i have wooden pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________A_____D___QR___R_N___GGQKCN___I__CG__G__ER__I___DID__H___RG_A___QN_CDRIWPC___IDD\n",
      "__C_____HQ_GEA_E___D___QR___R_N___GG__CN______CG__G__ER______DID__HNLYRG_AG__QN_CD________IDD\n",
      "__C_____HQNGEA_E___D___QRIWWR_N___GG__C____I__CG__G__ER__I___DID__HIC_RG_A____N_CDR___C___IDD\n",
      "__C_____HQ_GEA_E___D___QR___R_N___GG__CN___I__CGNPG__ER__I___DI_______RG_AG__QN_CDR________DD\n",
      "__C_____HQ_GE______DN__QR___R_N___GG__CN___I__CG__GIFER__I___DID__H___RGSAG__QN_CDR___C___IDD\n",
      "__C_____HQ_GEA_E___D___QR___R_N___GG__CN___I__CG__G__ER__I___DID__H____GKMYSMQN_CDR___C___IDD\n",
      "__C_____HQ_G_______D___QR___R_NFREGG__CN___I__CG__G__ER__I___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "__C_____HQ_GEA_EAIID___QR___R_M___G____N_______G__GC_EWANI___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "________HQ_GEA_E___DSMMQR___R_____GW__CN___I__CG__G__ER__ILCFDID__H___RG_AG__QN_C_____C___IDD\n",
      "__C_____HQ_GEA_E___D___Q______N___GG__CN___I__CG__I__ER__I___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "HKC_____HQ_GEA_E___D___QR___R_N___GGL_CN___I__CG__G__ER__T____ID__H___RG_AG__QN_CDR___C___IDD\n",
      "__C___KIHQ_GEA_E___D___QR___R_NH__GG__CNTHYI__CG__G__ER__I____ID__H___RG_AG__QN_CDR___C___IDD\n",
      "__C_____HQ_GEA_____D___QR___R_N___GG__CN___I__CG__G__ER__I___DID__H____G_____QN_C_________IDD\n",
      "LFC_____HQ_GEA_E___D___QR___R__________N_______G__G__ER__I___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "__CHQNKCH__GEA_E___D___QR___R_NMP_GG__CN___I__CG__G__ER__I___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "__C_____HQ_GEA_E___D___QR___R_Y___H___CN___I__CG__G__ER__I___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "__C_____HQ_GEA_E________R___R_N___GG__CN___IGTCG__G__ER_______ID__H___R______QN_CDR___CFSWIDD\n",
      "__C_____HQ_GEA_E___D___QR___RCN___GG__CN___I__CG__Q__SR__I___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "__C_____H__AEHQE___D___QR___R_N___GG__CN__GL__WD__G__ER__I___DID__H___RG_AG__QN_CDR___C___IDD\n",
      "________HQ_GEA_________QR___R_N___GG__CN___I__CG__G__ER__I___DIDPNH___RG_AG__QN_N_____C___IDD\n"
     ]
    }
   ],
   "source": [
    "# Multiple alignment using Pam_def\n",
    "\n",
    "# Creating tree\n",
    "tree = WPGMA(*mutation_dist(strings_mass, PAM_default))\n",
    "\n",
    "# Creating consensus\n",
    "cons = multiple_alignment(strings_mass, tree, PAM_default)\n",
    "\n",
    "for key in strings_mass:\n",
    "    print(align_pair_cons(cons, strings_mass[key], PAM_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__A__D__Q_RRNG___GQ______K_____CN____I__CGG__ER_I___DIDH__RG__AQNCDRIWPCIDD\n",
      "__C__H__Q_GEAE___DQ__R___RN_GG_CN_______CGG__ERDI___DHNL_YRG_AGQNCD_____IDD\n",
      "__C__H__QNGEAE___DQ__RIWWRN_GG_C_____I__CGG__ER_I___DIDH__IC_RGANCDR___CIDD\n",
      "__C__H__Q_GEAE___DQ__R___RN_GG_CN____I__CGN__PG_E___RIDI__RG_AGQNCDR_____DD\n",
      "__C__H__Q_GE_D___NQ__R___RN_GG_CN____I__CGGIFER_I___DIDH__RGSAGQNCDR___CIDD\n",
      "__C__H__Q_GEAE___DQ__R___RN_GG_CN____I__CGG__ER_I___DIDHG_KMYSMQNCDR___CIDD\n",
      "__C__H__Q_GDQR___RN__F___RE_GG_CN____I__CGG__ER_I___DIDH__RG_AGQNCDR___CIDD\n",
      "__C__H__Q_GEAEAIIDQ__R___RM_GN_GG_______CEW__AN_I___DIDH__RG_AGQNCDR___CIDD\n",
      "_____H__Q_GEAE___DSMMQ___RR_GW_CN____I__CGG__ER_ILCFDIDH__RG_AGQNC_____CIDD\n",
      "__C__H__Q_GEAE___DQ______N__GG_CN____I__CGI__ER_I___DIDH__RG_AGQNCDR___CIDD\n",
      "K__C__H__Q_GEAE___DQ__R___RN_GGLCN____I__CGG__ER_T____IDH__RG_AGQNCDR___CIDD\n",
      "__CKIH__Q_GEAE___DQ__R___RNHGG_CNTHY_I__CGG__ER_I____IDH__RG_AGQNCDR___CIDD\n",
      "__C__H__Q_GEAD____Q__R___RN_GG_CN____I__CGG__ER_I___DIDH______GQNC______IDD\n",
      "LFC__H__Q_GEAE___DQ__R___R______N________GG__ER_I___DIDH__RG_AGQNCDR___CIDD\n",
      "__CHQNKCH_GEAE___DQ__R___RNMPGGCN____I__CGG__ER_I___DIDH__RG_AGQNCDR___CIDD\n",
      "__C__H__Q_GEAE___DQ__R___RY_H__CN____I__CGG__ER_I___DIDH__RG_AGQNCDR___CIDD\n",
      "__C__H__Q_GEAE_______R___RN_GG_CN____IGTCGG__ER_I_____DH__RQ_NCDRCFS___WIDD\n",
      "__C__H__Q_GEAE___DQ__R___RC_NGGCN____I__CGQ__SR_I___DIDH__RG_AGQNCDR___CIDD\n",
      "__C__H__A_EHQE___DQ__R___RN_GG_CN___GL__WDG__ER_I___DIDH__RG_AGQNCDR___CIDD\n",
      "_____H__Q_GEA_____Q__R___RN_GG_CN____I__CGG__ER_I___DIDP__NH_RGAGQNN___CIDD\n"
     ]
    }
   ],
   "source": [
    "# Выравниваем по матрице PAM_250\n",
    "\n",
    "# Creating tree\n",
    "tree = WPGMA(*mutation_dist(strings_mass, PAM_250))\n",
    "\n",
    "# Creating consensus\n",
    "cons = multiple_alignment(strings_mass, tree, PAM_250)\n",
    "\n",
    "for key in strings_mass:\n",
    "    print(align_pair_cons(cons, strings_mass[key], PAM_250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It can be seen that PAM_250 can strongly change result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
